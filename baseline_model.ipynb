{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import bs4 as bs\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/AOL-user-ct-collection/user-ct-test-collection-01.txt') as file:\n",
    "    data_aol_1 = [line.strip().split('\\t') for line in file.readlines()]\n",
    "    \n",
    "with open('datasets/AOL-user-ct-collection/user-ct-test-collection-02.txt') as file:\n",
    "    data_aol_2 = [line.strip().split('\\t') for line in file.readlines()]\n",
    "    \n",
    "with open('datasets/AOL-user-ct-collection/user-ct-test-collection-03.txt') as file:\n",
    "    data_aol_3 = [line.strip().split('\\t') for line in file.readlines()]\n",
    "    \n",
    "with open('datasets/AOL-user-ct-collection/user-ct-test-collection-04.txt') as file:\n",
    "    data_aol_4 = [line.strip().split('\\t') for line in file.readlines()]\n",
    "    \n",
    "with open('datasets/AOL-user-ct-collection/user-ct-test-collection-05.txt') as file:\n",
    "    data_aol_5 = [line.strip().split('\\t') for line in file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/AOL-user-ct-collection/user-ct-test-collection-06.txt') as file:\n",
    "    data_aol_6 = [line.strip().split('\\t') for line in file.readlines()]\n",
    "    \n",
    "with open('datasets/AOL-user-ct-collection/user-ct-test-collection-07.txt') as file:\n",
    "    data_aol_7 = [line.strip().split('\\t') for line in file.readlines()]\n",
    "    \n",
    "with open('datasets/AOL-user-ct-collection/user-ct-test-collection-08.txt') as file:\n",
    "    data_aol_8 = [line.strip().split('\\t') for line in file.readlines()]\n",
    "    \n",
    "with open('datasets/AOL-user-ct-collection/user-ct-test-collection-09.txt') as file:\n",
    "    data_aol_9 = [line.strip().split('\\t') for line in file.readlines()]\n",
    "    \n",
    "    \n",
    "with open('datasets/AOL-user-ct-collection/user-ct-test-collection-10.txt') as file:\n",
    "    data_aol_10 = [line.strip().split('\\t') for line in file.readlines()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим WordPunctTokenizer для разбиения на слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "for i in range(1, len(data_aol_1)):\n",
    "    data_aol_1[i][1] = ' '.join(tokenizer.tokenize(data_aol_1[i][1].lower()))\n",
    "\n",
    "for i in range(1, len(data_aol_2)):\n",
    "    data_aol_2[i][1] = ' '.join(tokenizer.tokenize(data_aol_2[i][1].lower()))\n",
    "\n",
    "for i in range(1, len(data_aol_3)):\n",
    "    data_aol_3[i][1] = ' '.join(tokenizer.tokenize(data_aol_3[i][1].lower()))\n",
    "\n",
    "for i in range(1, len(data_aol_4)):\n",
    "    data_aol_4[i][1] = ' '.join(tokenizer.tokenize(data_aol_4[i][1].lower()))\n",
    "\n",
    "for i in range(1, len(data_aol_5)):\n",
    "    data_aol_5[i][1] = ' '.join(tokenizer.tokenize(data_aol_5[i][1].lower()))\n",
    "\n",
    "for i in range(1, len(data_aol_6)):\n",
    "    data_aol_6[i][1] = ' '.join(tokenizer.tokenize(data_aol_6[i][1].lower()))\n",
    "\n",
    "for i in range(1, len(data_aol_7)):\n",
    "    data_aol_7[i][1] = ' '.join(tokenizer.tokenize(data_aol_7[i][1].lower()))\n",
    "    \n",
    "for i in range(1, len(data_aol_8)):\n",
    "    data_aol_8[i][1] = ' '.join(tokenizer.tokenize(data_aol_8[i][1].lower()))\n",
    "    \n",
    "for i in range(1, len(data_aol_9)):\n",
    "    data_aol_9[i][1] = ' '.join(tokenizer.tokenize(data_aol_9[i][1].lower()))\n",
    "    \n",
    "for i in range(1, len(data_aol_10)):\n",
    "    data_aol_10[i][1] = ' '.join(tokenizer.tokenize(data_aol_10[i][1].lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['AnonID', 'Query', 'QueryTime', 'ItemRank', 'ClickURL'],\n",
       " ['142', 'rentdirect . com', '2006-03-01 07:17:12'],\n",
       " ['142', 'www . prescriptionfortime . com', '2006-03-12 12:31:06'],\n",
       " ['142', 'staple . com', '2006-03-17 21:19:29'],\n",
       " ['142', 'staple . com', '2006-03-17 21:19:45'],\n",
       " ['142', 'www . newyorklawyersite . com', '2006-03-18 08:02:58'],\n",
       " ['142', 'www . newyorklawyersite . com', '2006-03-18 08:03:09'],\n",
       " ['142',\n",
       "  'westchester . gov',\n",
       "  '2006-03-20 03:55:57',\n",
       "  '1',\n",
       "  'http://www.westchestergov.com'],\n",
       " ['142', 'space . comhttp', '2006-03-24 20:51:24'],\n",
       " ['142', 'dfdf', '2006-03-24 22:23:07']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_aol_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aol = data_aol_1[1:] + data_aol_2[1:] + data_aol_3[1:] + data_aol_4[1:] + data_aol_5[1:] + data_aol_6[1:] + data_aol_7[1:] + data_aol_8[1:] + data_aol_9[1:]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aol_queries = [query[1] for query in data_aol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aol_queries_test =  [query[1] for query in data_aol_10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на распределение по кол-ву слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_words = [len(query.split()) for query in data_aol_queries]\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(count_words)\n",
    "plt.grid(ls=':')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333, 0, 7.0, 9.0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(count_words), np.min(count_words), np.percentile(count_words, 95), np.percentile(count_words, 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12233161', '', '2006-05-23 21:24:05']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_aol[np.argwhere(np.array(count_words) == 0)[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем насколько часто каждое слово встретилось перед предыдущими (n-1) словами.\n",
    "В нашем случаем будем рассматривать n = 2 или n = 3. \n",
    "\n",
    "К каждому запросу в конец добавим специальный символ EOS. А в \n",
    "начало несколько UNK, чтобы проводить подсчет для первых слов запроса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK, EOS = \"_UNK_\", \"_EOS_\"\n",
    "\n",
    "def count_ngrams(lines, n):\n",
    "    counts = defaultdict(Counter)\n",
    "    # counts[(word1, word2)][word3] = how many times word3 occured after (word1, word2)\n",
    "\n",
    "    for line in lines:\n",
    "        line = (UNK + ' ')* (n - 1) + line + ' ' + EOS\n",
    "        words = line.split()\n",
    "        for i in range(n - 1, len(words)):\n",
    "            counts[tuple(words[i - n + 1: i])][words[i]] += 1\n",
    "    \n",
    "    return counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-gram Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пишем класс для статистической n-граммной языковой модели. \n",
    "\n",
    "Она посчитывает вероятности вида $P(word_2 | word_1)$ при n = 2 и $P(word_3 | word_1, word_2)$ при n = 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramLanguageModel:    \n",
    "    def __init__(self, lines, n):\n",
    "        self.n = n\n",
    "    \n",
    "        counts = count_ngrams(lines, self.n)\n",
    "        \n",
    "        self.probs = defaultdict(Counter)\n",
    "        # probs[(word1, word2)][word3] = P(word3 | word1, word2)\n",
    "        \n",
    "        for prev_words in counts.keys():\n",
    "            count_prefix = 0\n",
    "            for word in counts[prev_words].keys():\n",
    "                count_prefix += counts[prev_words][word]\n",
    "            for word in counts[prev_words].keys():\n",
    "                self.probs[prev_words][word] = counts[prev_words][word] / count_prefix\n",
    "            \n",
    "    def get_possible_next_tokens(self, prefix):\n",
    "        \"\"\"\n",
    "        :param prefix: string with space-separated prefix tokens\n",
    "        :returns: a dictionary {token : it's probability} for all tokens with positive probabilities\n",
    "        \"\"\"\n",
    "        prefix = prefix.split()\n",
    "        prefix = prefix[max(0, len(prefix) - self.n + 1):]\n",
    "        prefix = [ UNK ] * (self.n - 1 - len(prefix)) + prefix\n",
    "        return self.probs[tuple(prefix)]\n",
    "    \n",
    "    def get_next_token_prob(self, prefix, next_token):\n",
    "        \"\"\"\n",
    "        :param prefix: string with space-separated prefix tokens\n",
    "        :param next_token: the next token to predict probability for\n",
    "        :returns: P(next_token|prefix) a single number, 0 <= P <= 1\n",
    "        \"\"\"\n",
    "        return self.get_possible_next_tokens(prefix).get(next_token, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строим языковую модель для n = 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = NGramLanguageModel(data_aol_queries, n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на предсказания нашей модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_EOS_',\n",
       " 'arts',\n",
       " 'and',\n",
       " 'translation',\n",
       " 'translator',\n",
       " 'of',\n",
       " 'development',\n",
       " 'in',\n",
       " 'classes',\n",
       " 'for',\n",
       " 'learning',\n",
       " 'schools',\n",
       " 'pathology',\n",
       " 'books',\n",
       " 'javascript',\n",
       " 'disorder',\n",
       " 'pathologist',\n",
       " 'translations',\n",
       " 'lessons',\n",
       " 'sample',\n",
       " 'alphabet',\n",
       " 'courses',\n",
       " '.',\n",
       " 'is',\n",
       " 'delays',\n",
       " 'us',\n",
       " 'acquisition',\n",
       " 'lesson',\n",
       " 'programs',\n",
       " 'school',\n",
       " 'examples',\n",
       " 'dictionary',\n",
       " 'learners',\n",
       " 'used',\n",
       " 'interpreter',\n",
       " 'institute',\n",
       " 'newspapers',\n",
       " 'requirements',\n",
       " 'center',\n",
       " 'tools',\n",
       " 'converter',\n",
       " 'don',\n",
       " 'instruction',\n",
       " 'translators',\n",
       " 'to',\n",
       " 'pragmatics',\n",
       " 'being',\n",
       " 'pathologists',\n",
       " 'program',\n",
       " 'software',\n",
       " 'association',\n",
       " 'class',\n",
       " 'disorders',\n",
       " 'graphic',\n",
       " 'that',\n",
       " 'assessment',\n",
       " 'en',\n",
       " 'master',\n",
       " 'easier',\n",
       " 'trivia',\n",
       " 'therapist',\n",
       " '-',\n",
       " 'academy',\n",
       " 'speech',\n",
       " 'immersion',\n",
       " 'based',\n",
       " 'delay',\n",
       " 'tapes',\n",
       " 'cds',\n",
       " 'les',\n",
       " 'pictures',\n",
       " 'history',\n",
       " 'preference',\n",
       " 'posters',\n",
       " 'flash',\n",
       " 'chart',\n",
       " 'pack',\n",
       " 'cd',\n",
       " 'calculator',\n",
       " 'course',\n",
       " 'hearing',\n",
       " 'numbers',\n",
       " 'spoken',\n",
       " 'icon',\n",
       " 'tourist',\n",
       " 'chat',\n",
       " 'online',\n",
       " 'at',\n",
       " 'tool',\n",
       " 'chats',\n",
       " 'english',\n",
       " 'zaire',\n",
       " 'summer',\n",
       " 'bible',\n",
       " 'centers',\n",
       " 'writing',\n",
       " 'michael',\n",
       " '2001',\n",
       " 'conferences',\n",
       " 'dictionaries',\n",
       " '0',\n",
       " 'skills',\n",
       " 'interpretations',\n",
       " 'on',\n",
       " 'sheets',\n",
       " 'exchange',\n",
       " 'clip',\n",
       " 'study',\n",
       " 'acquistion',\n",
       " 'box',\n",
       " 'example',\n",
       " 'corrective',\n",
       " 'delayed',\n",
       " 'testing',\n",
       " 'therapists',\n",
       " 'you',\n",
       " 'usage',\n",
       " 'settings',\n",
       " 'i',\n",
       " 'group',\n",
       " 'log',\n",
       " 'rule',\n",
       " 'proficiency',\n",
       " 'fairy',\n",
       " 'mp3',\n",
       " 'graphics',\n",
       " 'audio',\n",
       " 'version',\n",
       " 'translater',\n",
       " 'diversity',\n",
       " 'bibles',\n",
       " 'aptitude',\n",
       " 'music',\n",
       " 'peculiarities',\n",
       " 'intervention',\n",
       " 'modifications',\n",
       " 'photos',\n",
       " 'voiceover',\n",
       " 'honor',\n",
       " 'during',\n",
       " 'milestones',\n",
       " 'song',\n",
       " 'garemin',\n",
       " 'tutorial',\n",
       " 'teachers',\n",
       " 'therapy',\n",
       " 'videos',\n",
       " 'required',\n",
       " 'linked',\n",
       " 'did',\n",
       " 'monterey',\n",
       " 'e',\n",
       " 'flow',\n",
       " 'jobs',\n",
       " 'does',\n",
       " 'letters',\n",
       " 'note',\n",
       " 'www',\n",
       " 'teacher',\n",
       " 'troy',\n",
       " 'from',\n",
       " 'worship',\n",
       " 'means',\n",
       " 'intensive',\n",
       " 'choice',\n",
       " 'different',\n",
       " 'he',\n",
       " 'printable',\n",
       " 'displayed',\n",
       " 'polish',\n",
       " 'definitions',\n",
       " 'mold',\n",
       " 'do',\n",
       " 'picture',\n",
       " 'words',\n",
       " 'specialist',\n",
       " 'download',\n",
       " 'processing',\n",
       " 'preferences',\n",
       " 'barriers',\n",
       " 'tshirts',\n",
       " 'ductionary',\n",
       " 'idioms',\n",
       " 'terms',\n",
       " 'free',\n",
       " 'poetry',\n",
       " 'imagery',\n",
       " 'packs',\n",
       " 'studies',\n",
       " 'putting',\n",
       " 'games',\n",
       " 'cartoon',\n",
       " 'quizzes',\n",
       " 'id',\n",
       " 'systems',\n",
       " 'teaching',\n",
       " 'organization',\n",
       " 'verbs',\n",
       " 'comprehension',\n",
       " 'conversion',\n",
       " 'conventions',\n",
       " 'asl',\n",
       " 'villages',\n",
       " 'barrier',\n",
       " 'dvd',\n",
       " '1943',\n",
       " 'into',\n",
       " 'durand',\n",
       " 'problems',\n",
       " 'network',\n",
       " 'interpreters',\n",
       " 'phonetic',\n",
       " 'how',\n",
       " 'abroad',\n",
       " 'transaltion',\n",
       " 'raith',\n",
       " 'system',\n",
       " 'if',\n",
       " 'by',\n",
       " 'exam',\n",
       " 'disc',\n",
       " 'toys',\n",
       " 'education',\n",
       " 'dept',\n",
       " 'phrases',\n",
       " 'tests',\n",
       " 'graded',\n",
       " 'thank',\n",
       " 'information',\n",
       " 'a',\n",
       " 'weather',\n",
       " 'websites',\n",
       " 'international',\n",
       " 'clothing',\n",
       " 'chicopee',\n",
       " 'agriculture',\n",
       " 'publishing',\n",
       " 'bar',\n",
       " 'proper',\n",
       " 'boro',\n",
       " 'empower',\n",
       " 'its',\n",
       " 'friends',\n",
       " 'women',\n",
       " 'libraries',\n",
       " 'art',\n",
       " 'test',\n",
       " 'journals',\n",
       " 'arithematic',\n",
       " 'facial',\n",
       " 'aol',\n",
       " 'the',\n",
       " 'observation',\n",
       " 'with',\n",
       " 'are',\n",
       " 'basics',\n",
       " 'italian',\n",
       " 'wedding',\n",
       " 'as',\n",
       " 'colleges',\n",
       " 'major',\n",
       " 'lyrics',\n",
       " 'servise',\n",
       " 'get',\n",
       " 'they',\n",
       " 'matters',\n",
       " 'extending',\n",
       " 'confusion',\n",
       " 'known',\n",
       " 'traslator',\n",
       " 'groups',\n",
       " 'kreyol',\n",
       " 'public',\n",
       " 'brain',\n",
       " 'bill',\n",
       " 'plugins',\n",
       " 'sign',\n",
       " 'san',\n",
       " 'humor',\n",
       " 'inventor',\n",
       " 'meetup',\n",
       " 'came',\n",
       " 'activities',\n",
       " 'notes',\n",
       " 'play',\n",
       " 'written',\n",
       " 'lab',\n",
       " 'og',\n",
       " 'fair',\n",
       " 'logos',\n",
       " 'wisconsin',\n",
       " '..',\n",
       " 'use',\n",
       " 'files',\n",
       " 'umass',\n",
       " 'hebrew',\n",
       " 'case',\n",
       " 'constructs',\n",
       " 'college',\n",
       " 'ease',\n",
       " 'animals',\n",
       " 'support',\n",
       " 'island',\n",
       " 'humphries',\n",
       " 'fast',\n",
       " 'methods',\n",
       " 'scale',\n",
       " 'reviews',\n",
       " 'gabon',\n",
       " 'central',\n",
       " 'cameroon',\n",
       " 'disciplines',\n",
       " '&',\n",
       " 'projects',\n",
       " 'deficits',\n",
       " 'arm',\n",
       " 'materials',\n",
       " 'curriculum',\n",
       " 'department',\n",
       " 'society',\n",
       " \"'\",\n",
       " 'symbols',\n",
       " 'kanada',\n",
       " 'disorderhttp',\n",
       " 'rights',\n",
       " 'country',\n",
       " 'alphebet',\n",
       " 'usa',\n",
       " 'normalize',\n",
       " 'rome',\n",
       " 'slogans',\n",
       " 'technologies',\n",
       " 'occ',\n",
       " 'rules',\n",
       " 'winter',\n",
       " 'literacy',\n",
       " 'learner',\n",
       " 'c',\n",
       " 'activites',\n",
       " 'homework',\n",
       " 'elementary',\n",
       " 'students',\n",
       " 'french',\n",
       " 'spanish',\n",
       " 'skill',\n",
       " 'dissertations',\n",
       " 'commentary',\n",
       " 'their',\n",
       " 'statistics',\n",
       " 'childrens',\n",
       " 'criteria',\n",
       " 'state',\n",
       " 'basic',\n",
       " 'characteristics',\n",
       " 'clicues',\n",
       " 'offered',\n",
       " 'characters',\n",
       " 'ronna',\n",
       " 'field',\n",
       " 'ka',\n",
       " 'plus',\n",
       " 'research',\n",
       " 'devepment',\n",
       " 'samples',\n",
       " 'audibles',\n",
       " 'literature',\n",
       " 'before',\n",
       " 'but',\n",
       " 'setting',\n",
       " 'searh',\n",
       " 'website',\n",
       " 'getting',\n",
       " 'news',\n",
       " 'form',\n",
       " 'phonograph',\n",
       " 'phone',\n",
       " 'review',\n",
       " 'stars',\n",
       " 'karaoke',\n",
       " 'definition',\n",
       " 'between',\n",
       " 'new',\n",
       " 'services',\n",
       " 'font',\n",
       " 'basque',\n",
       " 'sound',\n",
       " 'specialists',\n",
       " 'camp',\n",
       " 'show',\n",
       " 'this',\n",
       " 'email',\n",
       " 'foreign',\n",
       " 'dance',\n",
       " 'chiopee',\n",
       " 'aloff',\n",
       " 'prepare',\n",
       " 'content',\n",
       " 'frühlingsfreude',\n",
       " 'fort',\n",
       " 'int',\n",
       " 'accepted',\n",
       " 'scholarships',\n",
       " 'realaudio',\n",
       " 'readingp',\n",
       " 'reading',\n",
       " 'tranlator',\n",
       " 'superstision',\n",
       " 'superstition',\n",
       " 'preferances',\n",
       " 'map',\n",
       " 'questions',\n",
       " 'prefernces',\n",
       " 'scool',\n",
       " 'resource',\n",
       " 'jerusalem',\n",
       " 'jesus',\n",
       " 'cartooclimate',\n",
       " 'camaroon',\n",
       " 'broken',\n",
       " 'chicago',\n",
       " 'sampleprograms',\n",
       " 'arithematicsample',\n",
       " 'one',\n",
       " 'two',\n",
       " 'book',\n",
       " 'data',\n",
       " 'bittorent',\n",
       " 'examination',\n",
       " 'ranslators',\n",
       " 'help',\n",
       " 'vhs',\n",
       " 'tigerius',\n",
       " 'print',\n",
       " 'science',\n",
       " 'acquisiton',\n",
       " 'good',\n",
       " 'manual',\n",
       " 'sheet',\n",
       " 'christian',\n",
       " 'sermons',\n",
       " 'alphbet',\n",
       " 'mechanics',\n",
       " 'so',\n",
       " 'line',\n",
       " 'hau',\n",
       " 'disorde',\n",
       " 'fourth',\n",
       " 'tutors',\n",
       " 'portfolio',\n",
       " 'student',\n",
       " 'video',\n",
       " '--',\n",
       " 'pronunciation',\n",
       " 'family',\n",
       " 'room',\n",
       " '20',\n",
       " 'develpment',\n",
       " 'word',\n",
       " 'modernism',\n",
       " 'touris',\n",
       " 'rossetta',\n",
       " 'anastasia',\n",
       " 'instructors',\n",
       " 'named',\n",
       " 'interpreator',\n",
       " 'project',\n",
       " 'shall',\n",
       " 'stereotyping',\n",
       " 'clothes',\n",
       " 'festival',\n",
       " 'interpreting',\n",
       " 'bridges',\n",
       " '20of',\n",
       " 'everywhere',\n",
       " 'difficulty',\n",
       " 'fonts',\n",
       " 'names',\n",
       " 'special',\n",
       " 'printouts',\n",
       " 'pathalogist',\n",
       " 'perception',\n",
       " 'idol',\n",
       " 'roundup',\n",
       " 'standards',\n",
       " 'pashtoon',\n",
       " 'self',\n",
       " 'pamela',\n",
       " 'learn',\n",
       " 'translatoer',\n",
       " 'interperter',\n",
       " 'newspaper',\n",
       " 'publications',\n",
       " 'cursrss',\n",
       " 'children',\n",
       " 'circle',\n",
       " 'short',\n",
       " 'translate',\n",
       " 'patholist',\n",
       " 'vowels',\n",
       " 'ceu',\n",
       " 'war',\n",
       " 'making',\n",
       " 'makers',\n",
       " 'steps',\n",
       " 'kindergarten',\n",
       " 'translor',\n",
       " 'interpitations',\n",
       " 'essay',\n",
       " 'past',\n",
       " 'evening',\n",
       " 'paper',\n",
       " 'spoke',\n",
       " 'world',\n",
       " 'aquisition',\n",
       " 'stories',\n",
       " 'unonsciously',\n",
       " 'institutes',\n",
       " 'orlando',\n",
       " 'weina',\n",
       " 'rona',\n",
       " 'through',\n",
       " 'pictorial',\n",
       " 'beginnings',\n",
       " 'helps',\n",
       " 'service',\n",
       " 'was',\n",
       " 'pls',\n",
       " 'impirment',\n",
       " 'handshape',\n",
       " 'l',\n",
       " 'tarnslation',\n",
       " 'iroquois',\n",
       " 'drama',\n",
       " 'awards',\n",
       " 'puzzles',\n",
       " 'regrets',\n",
       " 'round',\n",
       " 'convertor',\n",
       " 'communication',\n",
       " 'an',\n",
       " 'tranlation',\n",
       " 'interpretering',\n",
       " 'come',\n",
       " 'stimulation',\n",
       " 'transulator',\n",
       " 'affect',\n",
       " 'helping',\n",
       " 'kristen',\n",
       " 'translated',\n",
       " 'training',\n",
       " 'los',\n",
       " 'la',\n",
       " 'exams',\n",
       " 'tutorials',\n",
       " 'changes',\n",
       " 'prefernse',\n",
       " 'preferance',\n",
       " 'islands',\n",
       " 'asscociation',\n",
       " 'workshop',\n",
       " 'jacksonville',\n",
       " 'dating',\n",
       " 'quotes',\n",
       " 'vocabulary',\n",
       " 'scholls',\n",
       " 'translaters',\n",
       " 'scottish',\n",
       " 'coure',\n",
       " 'chapters',\n",
       " 'sites',\n",
       " 'reeks',\n",
       " 'medical',\n",
       " 'sofware',\n",
       " 'englishnederlandsportuguêsdeutschfrançaisitalianoespañol',\n",
       " 'place',\n",
       " 'songs',\n",
       " 'pathalogy',\n",
       " 'textbooks',\n",
       " 'patholoy',\n",
       " 'experience',\n",
       " 'band']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_probs = lm.get_possible_next_tokens('language')\n",
    "sorted(token_probs.keys(), key=token_probs.get, reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И напишем функцию, возвращающую наболее вероятное слова по префиксу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_token(lm, prefix):\n",
    "    token_probs = lm.get_possible_next_tokens(prefix)\n",
    "    return np.array(list(token_probs.keys()))[np.argmax(list(token_probs.values()))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что в нашем случае наиболее вероятное - закончить запрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'com'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_token(lm, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'com'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_token(lm, 'www .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'to'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_token(lm, 'how')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну ничего так, но глуповато : смотрим только на один токен назад."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь посчитаем метрику - перплексию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(lm, lines, min_logprob=np.log(10 ** -50.)):\n",
    "    log_perplexity = 0\n",
    "    count_words = 0\n",
    "    for line in lines:\n",
    "        sent = line.split()\n",
    "        prefix = [UNK] * (lm.n - 1)\n",
    "        prob = lm.get_next_token_prob(' '.join(prefix), sent[0])\n",
    "        if prob > 0:\n",
    "            addition = np.log(prob)\n",
    "            if addition < min_logprob:\n",
    "                addition = min_logprob\n",
    "            log_perplexity += addition\n",
    "        else:\n",
    "            log_perplexity += min_logprob\n",
    "\n",
    "        count_words += len(sent) + 1\n",
    "        for i, token in enumerate(sent[:-1]):\n",
    "            prefix = prefix[1:] + [token]\n",
    "            prob = lm.get_next_token_prob(' '.join(prefix), sent[i + 1])\n",
    "            if prob > 0:\n",
    "                addition = np.log(prob)\n",
    "                if addition < min_logprob:\n",
    "                    addition = min_logprob\n",
    "                log_perplexity += addition\n",
    "            else:\n",
    "                log_perplexity += min_logprob\n",
    "            \n",
    "        prefix = prefix[1:] + [sent[-1]]\n",
    "        prob = lm.get_next_token_prob(' '.join(prefix), EOS)\n",
    "        if prob > 0:\n",
    "            addition = np.log(prob)\n",
    "            if addition < min_logprob:\n",
    "                addition = min_logprob\n",
    "            log_perplexity += addition\n",
    "        else:\n",
    "            log_perplexity += min_logprob\n",
    "            \n",
    "    return np.exp(-log_perplexity / count_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232788250.5037612"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity(lm, data_aol_queries_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на результат модели на 3-граммах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = NGramLanguageModel(data_aol_queries, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'google'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_token(lm, 'www .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "762957792024751.1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity(lm, data_aol_queries_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перплексия взрывается"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kneser-Ney Language Model\n",
    "\n",
    "Теперь к нашей модели применим сглаживание Кнейзера-Нея. Для этого напишем похожий класс.\n",
    "Кажется, что для нашей задачи сглаживание очень нужно так как многие вопросы встречаются только один раз и могут вообще больше никогда не встретиться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will need a special function that reverses our counts dictionary\n",
    "def reverse_counts(counts):\n",
    "    rev = defaultdict(Counter)\n",
    "    for prefix in counts:\n",
    "        for key, value in counts[prefix].items():\n",
    "            rev[key][prefix[0]] += value\n",
    "    return rev\n",
    "    \n",
    "\n",
    "class KneserNeyLanguageModel(NGramLanguageModel): \n",
    "    \"\"\" this code is an example, no need to change anything \"\"\"\n",
    "    def __init__(self, lines, n, delta=1.0):\n",
    "        self.n = n\n",
    "        \n",
    "        # In case of unigrams we should still count for bigrams\n",
    "        self.counts = count_ngrams(lines, max(self.n, 2))\n",
    "        self.vocab = set(token for token_counts in self.counts.values() for token in token_counts)\n",
    "        self.probs = defaultdict(Counter)\n",
    "        self.delta = delta\n",
    "    \n",
    "        if n >= 2:\n",
    "            self.prev_lm = KneserNeyLanguageModel(lines, n - 1, delta=delta)\n",
    "            for prefix in self.counts:\n",
    "                token_counts = self.counts[prefix]\n",
    "                total_count = np.sum(list(token_counts.values()))\n",
    "                lambd = delta / total_count * len(token_counts)\n",
    "                self.probs[prefix] = {token: np.max(token_counts[token] - delta, 0) / total_count\n",
    "                                      + lambd * self.prev_lm.get_next_token_prob(' '.join(prefix[1:]), token)\n",
    "                                              for token in token_counts}\n",
    "        else:\n",
    "            # See https://nlp.stanford.edu/~wcmac/papers/20050421-smoothing-tutorial.pdf\n",
    "            # We have to reverse the tokens to efficiently compute N_1+\n",
    "            self.counts1 = count_ngrams(lines, 1) # Will need later\n",
    "            rev_counts = reverse_counts(self.counts)\n",
    "            sum_words = sum([len(rev_counts[postfix]) for postfix in rev_counts])\n",
    "            for word in self.vocab:\n",
    "                self.probs[tuple()][word] = len(rev_counts[word]) / sum_words\n",
    "\n",
    "    def get_possible_next_tokens(self, prefix):\n",
    "        token_probs = super().get_possible_next_tokens(prefix)\n",
    "        missing_prob_total = 1.0 - sum(token_probs.values())\n",
    "        missing_prob = missing_prob_total / max(1, len(self.vocab) - len(token_probs))\n",
    "        return {token: token_probs.get(token, missing_prob) for token in self.vocab}\n",
    "    \n",
    "    def get_next_token_prob(self, prefix, next_token):\n",
    "        token_probs = super().get_possible_next_tokens(prefix)\n",
    "        if next_token in token_probs:\n",
    "            return token_probs[next_token]\n",
    "        else:\n",
    "            # If n is equal to 1 and we haven't met this prefix, then the probability should be 0\n",
    "            if self.n == 1:\n",
    "                return 0\n",
    "            \n",
    "            # Pad the sequence if necessary\n",
    "            prefix_p = tuple(prefix.strip().split())\n",
    "            if len(prefix_p) < self.n - 1:\n",
    "                prefix_p = (UNK,) * (self.n - 1 - len(prefix_p))  + prefix_p\n",
    "            token_counts = self.counts[prefix_p]\n",
    "            total_count = np.sum(list(token_counts.values()))\n",
    "            \n",
    "            if total_count > 0:\n",
    "                # If we haven't met this prefix, just apply backoff!\n",
    "                lambd = self.delta / total_count * len(token_counts)\n",
    "                return lambd * self.prev_lm.get_next_token_prob(' '.join(prefix_p[1:]), next_token)\n",
    "            else:\n",
    "                # Otherwise, make normalized backoff\n",
    "                return self.prev_lm.get_next_token_prob(' '.join(prefix_p[1:]), next_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = KneserNeyLanguageModel(data_aol_queries, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'com'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_token(lm, 'www .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1748.3296772504434"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity(lm, data_aol_queries_test[:100000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перплексия стала гораздо лучше. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n = 2</td>\n",
       "      <td>2.327883e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n = 3</td>\n",
       "      <td>7.629578e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kneser-Ney smooting, n = 3</td>\n",
       "      <td>1.892584e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model    perplexity\n",
       "0                       n = 2  2.327883e+08\n",
       "1                       n = 3  7.629578e+14\n",
       "2  Kneser-Ney smooting, n = 3  1.892584e+05"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['model'] = ['n = 2', 'n = 3', 'Kneser-Ney smooting, n = 3']\n",
    "df['perplexity'] = [232788250.5037612, 762957792024751.1, 189258.402469]\n",
    "\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
